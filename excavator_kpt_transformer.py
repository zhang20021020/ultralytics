# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

# excavator_kpt_transformer.py
import math
from typing import Optional

import torch
import torch.nn as nn


# -----------------------------
# å‡ ä½•ç‰¹å¾æ„é€ ï¼ˆå¯é€‰ä½†å¼ºçƒˆå»ºè®®ï¼‰
# -----------------------------
def build_geo_features(kpts: torch.Tensor) -> torch.Tensor:
    """
    è¾“å…¥:  kpts: (B, T, K, 3)  å…¶ä¸­æœ€åä¸€ç»´ä¸º (x, y, v) è¾“å‡º:  geo:  (B, T, G)    å‡ ä½•ç‰¹å¾ï¼ŒGä¸ºç‰¹å¾ç»´æ•°.

    è¯´æ˜:  ä¸‹æ–¹æŒ‰ä½ çš„ç¤ºæ„ç‚¹ä½åšäº†å‡ ç§å¸¸ç”¨å‡ ä½•é‡ï¼š
      - é“²æ–—å°–ç«¯(1) / é“²æ–—-åŠ¨è‡‚é“°ç‚¹(2) / åŠ¨è‡‚ä¸­æ®µ(3) / åŠ¨è‡‚æ ¹éƒ¨(4)
      - é©¾é©¶å®¤å‚è€ƒç‚¹(5) / åº•ç›˜ä¸­å¿ƒ(6) / å·¦å‰è½®(7) / å³åè½®(9)
    å¦‚ä½ çš„å…³é”®ç‚¹å®šä¹‰ä¸åŒï¼Œè¯·è‡ªè¡Œè°ƒæ•´ç´¢å¼•ã€‚.
    """
    # ç´¢å¼•æ¢æˆ 0-based
    idx = {
        "bucket_tip": 0,  # ç‚¹1
        "bucket_hinge": 1,  # ç‚¹2
        "boom_mid": 2,  # ç‚¹3
        "boom_root": 3,  # ç‚¹4
        "cabin": 4,  # ç‚¹5
        "chassis": 5,  # ç‚¹6
        "wheel_l": 6,  # ç‚¹7
        "wheel_r": 8,  # ç‚¹9
    }

    x = kpts[..., 0]  # (B, T, K)
    y = kpts[..., 1]  # (B, T, K)
    v = kpts[..., 2]  # (B, T, K)

    def _vec(a: int, b: int) -> tuple[torch.Tensor, torch.Tensor]:
        return x[..., b] - x[..., a], y[..., b] - y[..., a]

    # åŠ¨è‡‚å‘é‡: root->midï¼Œmid->hingeï¼Œé“²æ–—å‘é‡: hinge->tip
    vx_rm, vy_rm = _vec(idx["boom_root"], idx["boom_mid"])
    vx_mh, vy_mh = _vec(idx["boom_mid"], idx["bucket_hinge"])
    vx_ht, vy_ht = _vec(idx["bucket_hinge"], idx["bucket_tip"])

    # ä¸æ°´å¹³çº¿å¤¹è§’ï¼ˆ-pi~piï¼‰
    def angle(vx, vy):
        return torch.atan2(vy, vx)

    a_rm = angle(vx_rm, vy_rm)  # æ ¹åˆ°ä¸­æ®µ
    a_mh = angle(vx_mh, vy_mh)  # ä¸­æ®µåˆ°é“°ç‚¹
    a_ht = angle(vx_ht, vy_ht)  # é“°ç‚¹åˆ°é“²å°–ï¼ˆé“²æ–—è§’ï¼‰

    # æ®µé•¿ï¼ˆåšå°ºåº¦å½’ä¸€åŒ–ï¼šé™¤ä»¥ä¸¤è½®ä¸­å¿ƒè·ï¼‰
    # è½®è·è¿‘ä¼¼: å·¦å‰è½®(7) <-> å³åè½®(9) çš„è·ç¦»ï¼ˆå¦‚ä¸ºå±¥å¸¦è½¦ï¼Œå¯æ¢æˆä¸¤ç«¯æ¥è§¦ç‚¹ï¼‰
    dx_wr = x[..., idx["wheel_r"]] - x[..., idx["wheel_l"]]
    dy_wr = y[..., idx["wheel_r"]] - y[..., idx["wheel_l"]]
    wheel_span = torch.sqrt(dx_wr**2 + dy_wr**2).clamp_min(1e-4)

    def seg_len(vx, vy):
        return torch.sqrt(vx**2 + vy**2) / wheel_span

    len_rm = seg_len(vx_rm, vy_rm)
    len_mh = seg_len(vx_mh, vy_mh)
    len_ht = seg_len(vx_ht, vy_ht)

    # é“²æ–—å°–ç«¯ç›¸å¯¹åº•ç›˜ä¸­å¿ƒçš„é«˜åº¦å·®ï¼ˆy è½´æ–¹å‘ï¼Œyè¶Šå¤§ä»£è¡¨è¶Šé ä¸‹çš„è¯è¯·å–åï¼‰
    rel_h_tip = (y[..., idx["chassis"]] - y[..., idx["bucket_tip"]]) / wheel_span

    # å¯è§æ€§æ¯”ä¾‹ï¼ˆä¿è¯é®æŒ¡æ—¶æ¨¡å‹é²æ£’ï¼‰
    vis_ratio = (v > 0).float().mean(dim=-1)  # (B, T)

    # æ‹¼æ¥å‡ ä½•ç‰¹å¾
    geo = torch.stack([a_rm, a_mh, a_ht, len_rm, len_mh, len_ht, rel_h_tip, vis_ratio], dim=-1)  # (B, T, 8)

    # è§’åº¦å½’ä¸€åŒ–åˆ° [-1, 1]
    geo[..., 0:3] = geo[..., 0:3] / math.pi
    return geo


# -----------------------------
# å¯å­¦ä¹ ä½ç½®ç¼–ç 
# -----------------------------
class LearnablePositionalEncoding(nn.Module):
    def __init__(self, d_model: int, max_len: int = 1024):
        super().__init__()
        self.pe = nn.Parameter(torch.zeros(1, max_len, d_model))
        nn.init.trunc_normal_(self.pe, std=0.02)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # x: (B, T, d_model)
        T = x.size(1)
        return x + self.pe[:, :T, :]


# -----------------------------
# ä¸»æ¨¡å‹
# -----------------------------
class ExcavatorKPTTransformer(nn.Module):
    def __init__(
        self,
        num_keypoints: int = 9,
        use_visibility: bool = True,
        use_geo: bool = True,
        d_model: int = 256,
        nhead: int = 8,
        num_layers: int = 4,
        dim_feedforward: int = 512,
        dropout: float = 0.1,
        num_classes: int = 2,
        use_cls_token: bool = True,
        max_len: int = 1024,
    ):
        super().__init__()
        self.num_keypoints = num_keypoints
        self.use_visibility = use_visibility
        self.use_geo = use_geo
        self.use_cls_token = use_cls_token

        base_feat = 2 if not use_visibility else 3  # (x, y[, v])
        frame_in_dim = num_keypoints * base_feat

        # å¸§å†…çº¿æ€§æŠ•å½±
        self.frame_proj = nn.Sequential(nn.LayerNorm(frame_in_dim), nn.Linear(frame_in_dim, d_model))

        # å¯é€‰å‡ ä½•ç‰¹å¾åˆ†æ”¯
        geo_dim = 8 if use_geo else 0
        if use_geo:
            self.geo_proj = nn.Sequential(nn.LayerNorm(geo_dim), nn.Linear(geo_dim, d_model))

        # [CLS] token
        if use_cls_token:
            self.cls_token = nn.Parameter(torch.zeros(1, 1, d_model))
            nn.init.trunc_normal_(self.cls_token, std=0.02)

        self.pos_enc = LearnablePositionalEncoding(d_model, max_len=max_len)

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=dim_feedforward,
            dropout=dropout,
            batch_first=True,
            norm_first=True,
        )
        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

        # åˆ†ç±»å¤´
        self.head = nn.Sequential(nn.LayerNorm(d_model), nn.Linear(d_model, num_classes))

    def forward(self, kpts: torch.Tensor, lengths: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        kpts:    (B, T, K, 3)  -> (x, y, v)  å…¶ä¸­ v å¯é€‰
        lengths: (B,) æ¯ä¸ªæ ·æœ¬çš„æœ‰æ•ˆå¸§é•¿ã€‚è‹¥æä¾›ï¼Œå°†åš padding maskã€‚
        è¿”å›:    (B, num_classes) logits.
        """
        B, T, K, C = kpts.shape
        assert K == self.num_keypoints, "å…³é”®ç‚¹æ•°é‡ä¸åŒ¹é…"

        # é€‰æ‹©æ˜¯å¦ä½¿ç”¨ v
        if not self.use_visibility and C == 3:
            kpts = kpts[..., :2]  # ä¸¢å¼ƒ v
            C = 2

        frame_feat = kpts.reshape(B, T, K * C)  # (B, T, K*C)
        f_emb = self.frame_proj(frame_feat)  # (B, T, d)

        if self.use_geo:
            geo = build_geo_features(kpts)  # (B, T, 8)
            g_emb = self.geo_proj(geo)  # (B, T, d)
            x = f_emb + g_emb  # èåˆ
        else:
            x = f_emb

        # å¯é€‰ [CLS]
        if self.use_cls_token:
            cls = self.cls_token.expand(B, 1, -1)  # (B,1,d)
            x = torch.cat([cls, x], dim=1)  # (B, T+1, d)

        # ä½ç½®ç¼–ç 
        x = self.pos_enc(x)

        # padding mask: True è¡¨ç¤ºéœ€è¦maskï¼ˆæ— æ•ˆä½ç½®ï¼‰
        src_key_padding_mask = None
        if lengths is not None:
            pad = x.new_ones((B, x.size(1)), dtype=torch.bool)  # (B, T[+1])
            offset = 1 if self.use_cls_token else 0
            for i, L in enumerate(lengths.tolist()):
                pad[i, offset : offset + L] = False
            # å…¶ä½™ä½ç½®ä¸º Trueï¼ˆmaskï¼‰
            src_key_padding_mask = pad

        z = self.encoder(x, src_key_padding_mask=src_key_padding_mask)  # (B, T[+1], d)

        if self.use_cls_token:
            pooled = z[:, 0]  # [CLS]
        else:
            # å¯¹æœ‰æ•ˆå¸§å¹³å‡æ± åŒ–
            if lengths is None:
                pooled = z.mean(dim=1)
            else:
                mask = (~src_key_padding_mask).float()
                if self.use_cls_token:
                    mask = mask[:, 1:]  # å»æ‰CLS
                    feats = z[:, 1:, :]
                else:
                    feats = z
                denom = mask.sum(dim=1, keepdim=True).clamp_min(1e-6)
                pooled = (feats * mask.unsqueeze(-1)).sum(dim=1) / denom

        logits = self.head(pooled)
        return logits
